{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f5a9931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1451\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures as futures\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "from collections import Counter\n",
    "from typing import Generator, Iterator, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "import torch.utils.data as tud\n",
    "\n",
    "from squirrel.driver import JsonlDriver\n",
    "from squirrel.iterstream.torch_composables import SplitByWorker, TorchIterable, skip_k\n",
    "from squirrel.serialization import JsonSerializer\n",
    "from squirrel.store import SquirrelStore\n",
    "\n",
    "N_SHARDS = 20\n",
    "MIN_SAMPLES_PER_SHARD = 50\n",
    "MAX_SAMPLES_PER_SHARD = 100\n",
    "\n",
    "def create_data(test_folder: str) -> int:\n",
    "    \"\"\"Helper function to create test data.\"\"\"\n",
    "\n",
    "    def create_shard(id_: int, min: int, max: int) -> Tuple[int, int]:\n",
    "        num_samples = random.Random().randint(a=min, b=max)\n",
    "        store = SquirrelStore(url=test_folder, serializer=JsonSerializer())\n",
    "        shard = [{\"shard_idx\": id_, \"sample_idx\": idx} for idx in range(num_samples)]\n",
    "        store.set(key=str(id_), value=shard)\n",
    "        return id_, num_samples\n",
    "\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    with futures.ThreadPoolExecutor(max_workers=4) as pool:\n",
    "        futs = [pool.submit(create_shard, idx, MIN_SAMPLES_PER_SHARD, MAX_SAMPLES_PER_SHARD) for idx in range(N_SHARDS)]\n",
    "\n",
    "    n_samples = 0\n",
    "    for fut in futures.as_completed(futs):\n",
    "        shard_id, _n_samps = fut.result()\n",
    "        assert MIN_SAMPLES_PER_SHARD <= _n_samps <= MAX_SAMPLES_PER_SHARD\n",
    "        n_samples += _n_samps\n",
    "    \n",
    "    print(n_samples)\n",
    "    return n_samples\n",
    "\n",
    "def test_data() -> Tuple[str, int]:\n",
    "    \"\"\"Fixture for this modules test data\"\"\"\n",
    "\n",
    "    test_folder = tempfile.TemporaryDirectory()\n",
    "\n",
    "    n_samples = create_data(test_folder=test_folder.name)\n",
    "    return test_folder.name, n_samples\n",
    "\n",
    "test_data_folder, total_samples = test_data()\n",
    "\n",
    "it = (\n",
    "    JsonlDriver(test_data_folder)\n",
    "    # In order to not have duplication of all kinds of buffers, we need to limit the buffer size\n",
    "    # Increasing the buffer will lead to failing tests due to over-sampling.\n",
    "    .get_iter(shuffle_key_buffer=0, prefetch_buffer=0, shuffle_item_buffer=0, max_workers=0)\n",
    "    # .map(print)\n",
    "    # # change Image.open handles to np arrays which is pickable,\n",
    "    # # allowing python to send the objects to other processes.\n",
    "    .compose(SplitByWorker)\n",
    "    .shuffle(size=400)\n",
    "    .take(n=N_SHARDS * MIN_SAMPLES_PER_SHARD)\n",
    "    .compose(TorchIterable)\n",
    ")\n",
    "\n",
    "# dl = tud.DataLoader(it, batch_size=None, num_workers=4)\n",
    "# elems = [json.dumps(item) for item in dl]\n",
    "for item in it:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fb208e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
